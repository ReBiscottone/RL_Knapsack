{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this script, I try to use RL to solve the knapsack problem.\n",
    "This should not be an exciting project but just a warm up (for me at least) to understand hands-on RL, RNN, embeddings and such.\n",
    "\n",
    "The project starts with:\n",
    "- a nn to move from 2 features per object to 8\n",
    "- a LTSM with an internal state composed by 5 features\n",
    "- its output is fed to a fully connected layer that from 5 feature expands to the number of objects\n",
    "- a softmax decides which element to choose\n",
    "- If you chose objects whose weight is more than 1, the reward is -100\n",
    "\n",
    "Still to implement:\n",
    "- attention mechanism\n",
    "- mask to not choose 'wrong' objects\n",
    "\n",
    "As always, we start by importing useful libraries and defiening some boundary conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import torch \n",
    "import random\n",
    "import itertools    \n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "random.seed(1234)\n",
    "prize_min = 0\n",
    "prize_max = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we define the object class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ObjectCass:\n",
    "    \n",
    "    Prize = None\n",
    "    Weight = None\n",
    "    \n",
    "    def __init__(self, reward, weight):\n",
    "        \n",
    "        self.Prize = reward\n",
    "        self.Weight = weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we define the function to generate new instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GenerateANewInstance(num_objs):\n",
    "    \n",
    "    Objects = []\n",
    "    for i in range(len(num_objs)):\n",
    "        prize = round(random.uniform(prize_min, prize_max), 0)\n",
    "        weight = round(random.uniform(0, 1), 2)\n",
    "        obj = ObjectCass(prize,weight)\n",
    "        Objects.append(obj)\n",
    "    Object.append(ObjectCass(0,0)) # fake object representing that you don't pick up anything\n",
    "                                   # i.e. you stop picking up stuff\n",
    "    \n",
    "    return Objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we define a very general agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentClass:\n",
    "    def __init__(self):\n",
    "        self.total_reward = 0.0\n",
    "\n",
    "    def step(self, env):\n",
    "        \n",
    "        current_obs = env.get_observation() #this could be rmeoved I think\n",
    "        actions = env.get_actions()\n",
    "        reward = env.action(random.choice(actions))\n",
    "        self.total_reward += reward\n",
    "        \n",
    "        return action\n",
    "Agent = AgentClass()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I try to create a shallow NN. from the features of the input (which are 2), I want to output 10 features (whith one hidden layer of size 10 as well)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.2479, 0.2196, 0.2969, 0.2381, 0.2964, 0.2422, 0.2296, 0.2567,\n",
      "          0.2861, 0.2800],\n",
      "         [0.2371, 0.3081, 0.1691, 0.2747, 0.1790, 0.2802, 0.2762, 0.2382,\n",
      "          0.2011, 0.2167],\n",
      "         [0.2479, 0.2196, 0.2969, 0.2381, 0.2964, 0.2422, 0.2296, 0.2567,\n",
      "          0.2861, 0.2800],\n",
      "         [0.2670, 0.2528, 0.2370, 0.2490, 0.2282, 0.2353, 0.2647, 0.2485,\n",
      "          0.2267, 0.2233]]], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[[0.2479, 0.2196, 0.2969, 0.2381, 0.2964, 0.2422, 0.2296, 0.2567,\n",
      "          0.2861, 0.2800],\n",
      "         [0.2371, 0.3081, 0.1691, 0.2747, 0.1790, 0.2802, 0.2762, 0.2382,\n",
      "          0.2011, 0.2167],\n",
      "         [0.2479, 0.2196, 0.2969, 0.2381, 0.2964, 0.2422, 0.2296, 0.2567,\n",
      "          0.2861, 0.2800],\n",
      "         [0.2670, 0.2528, 0.2370, 0.2490, 0.2282, 0.2353, 0.2647, 0.2485,\n",
      "          0.2267, 0.2233]]], grad_fn=<SoftmaxBackward>)\n"
     ]
    }
   ],
   "source": [
    "class EmbeddingPlusLSTM(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, num_input, num_embeddings, num_h, num_output, batch_size):    \n",
    "        \n",
    "        super(EmbeddingPlusLSTM, self).__init__() # this is not really clear to me\n",
    "        \n",
    "        self.fc1 = torch.nn.Linear(num_input, num_embeddings)\n",
    "        self.fc2 = torch.nn.Linear(num_embeddings, num_embeddings)\n",
    "        self.lstm= torch.nn.LSTM(num_embeddings,  num_h)\n",
    "        self.fc3 = torch.nn.Linear(num_h, num_output)\n",
    "        \n",
    "        # here I set the first internal state of the RNN.\n",
    "        # I set it here and not in forwards otherwise it start with different h_0\n",
    "        # For now it's zero-initialied, but maybe there is something smarter \n",
    "        # that can be done.\n",
    "        \n",
    "        self.batch_size = batch_size \n",
    "        n_layers = 1                \n",
    "        self.hidden_state = torch.zeros(n_layers, self.batch_size, self.fc3.in_features)\n",
    "        self.cell_state = torch.zeros(n_layers, self.batch_size, self.fc3.in_features)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        \n",
    "        self.hidden = (self.hidden_state, self.cell_state)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        x = x[None, :, :] # I don't know why you have to add a dimension here\n",
    "        \n",
    "        self.hidden, cell_state = self.lstm(x, self.hidden)\n",
    "        x = self.fc3(self.hidden)        \n",
    "        x = torch.nn.functional.softmax(x, dim = 1)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "tensors = torch.tensor([[1., -1.],[2., 15.],[1., -1.],[20., 12.]])\n",
    "#tensors = torch.tensor([[1., -1.]])\n",
    "Net = EmbeddingPlusLSTM(2, 8, 5, 10, len(tensors)) \n",
    "# 2 is the number of features of an Object\n",
    "# 8 is the number of features for the embedding\n",
    "# 5 number of features for the hidden size of the rnn\n",
    "#10 is the number of output features\n",
    "# the last one is the batch size\n",
    "params = list(Net.parameters())\n",
    "\n",
    "x = Net(tensors)\n",
    "print(x)\n",
    "x = Net(tensors)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you should put the real RL framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Net = EmbeddingPlusLSTM(2, 8, 5, 10) \n",
    "# 2 is the number of features of an Object\n",
    "# 10 is the number of features for the embedding\n",
    "# 5 number of features for the hidden size of the rnn\n",
    "\n",
    "params = list(Net.parameters())\n",
    "#tensors = torch.tensor([[1., -1.],[2., 15.],[1., -1.],[2., 15.]])\n",
    "#tensors = torch.tensor([[1., -1.]])\n",
    "#x = Net(tensors)\n",
    "#print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "\n",
    "loss = criterion(output, target)\n",
    "print(loss)\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "# create your optimizer\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
    "\n",
    "# in your training loop:\n",
    "optimizer.zero_grad()   # zero the gradient buffers\n",
    "output = net(input)\n",
    "loss = criterion(output, target)\n",
    "loss.backward()\n",
    "optimizer.step()    # Does the update\n",
    "\n",
    "\n",
    "for i_counter in len(range(num_instances)):\n",
    "    num_objs = 10\n",
    "    Objects = GenerateANewInstance(num_objs)\n",
    "    total_reward = 0.0\n",
    "    total_steps = 0\n",
    "\n",
    "    while True:\n",
    "        choose action\n",
    "        observe reward\n",
    "        total_steps += 1\n",
    "        if action.Prize == 0 and action.Weight == 0:\n",
    "            break\n",
    "\n",
    "    print(\"Episode done in %d steps, total reward %.2f\" % (total_steps, Agent.totoal_reward))    \n",
    "    stop"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
