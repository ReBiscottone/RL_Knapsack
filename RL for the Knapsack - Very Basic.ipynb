{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this script, I try to use RL to solve the knapsack problem.\n",
    "This should not be an exciting project but just a warm up (for me at least) to understand hands-on RL, RNN, embeddings and such.\n",
    "\n",
    "The project starts with:\n",
    "- a nn to move from 2 features per object to 8\n",
    "- a LTSM with an internal state composed by 5 features\n",
    "- its output is fed to a fully connected layer that from 5 feature expands to the number of objects\n",
    "- a softmax decides which element to choose\n",
    "- If you chose objects whose weight is more than 1, the reward is -100\n",
    "- attention mechanism with glimpse\n",
    "\n",
    "Still to implement:\n",
    "- mask to not choose 'wrong' objects\n",
    "- for now, it works only wwith batches of one. Cahnge this\n",
    "\n",
    "As always, we start by importing useful libraries and defiening some boundary conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import torch \n",
    "import random\n",
    "import itertools    \n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "random.seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we define the object class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ObjectCass:\n",
    "    \n",
    "    Prize = None\n",
    "    Weight = None\n",
    "    \n",
    "    def __init__(self, reward, weight):\n",
    "        \n",
    "        self.Prize = reward\n",
    "        self.Weight = weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we define the function to generate new instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def GenerateANewInstance(num_objs):\n",
    "    \n",
    "    # fake code to control the instance I fed it.\n",
    "    # best solution = [1,0,1,0,1,0,1,0,1,0,1]\n",
    "    \n",
    "    Objects = []\n",
    "    for i in range(num_objs):\n",
    "        if i%2==1:\n",
    "            prize = 0.1\n",
    "            weight = 0.51\n",
    "            obj = ObjectCass(prize,weight)\n",
    "            Objects.append(obj)\n",
    "        else:\n",
    "            prize = 1\n",
    "            weight = 0.19\n",
    "            obj = ObjectCass(prize,weight)\n",
    "            Objects.append(obj)\n",
    "    Objects.append(ObjectCass(0,0)) # fake object representing that you don't pick up anything\n",
    "    \n",
    "    return Objects\n",
    "    \n",
    "    # real code    \n",
    "    \n",
    "#    Objects = []\n",
    "#    for i in range(num_objs):\n",
    "#        prize = round(random.uniform(prize_min, prize_max), 0)\n",
    "#        weight = round(random.uniform(0.01, 1), 2)\n",
    "#        obj = ObjectCass(prize,weight)\n",
    "#        Objects.append(obj)\n",
    "#    Objects.append(ObjectCass(0,0)) # fake object representing that you don't pick up anything\n",
    "#                                   # i.e. you stop picking up stuff\n",
    "#    \n",
    "#    return Objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actor Net. input dimension [num_objects] output dimensions [num_objects]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ActorNet(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, num_input_features, dim_kernel, num_embeddings, num_h, dim_W_a, dim_W_c, batch_size):    \n",
    "        \n",
    "        super(ActorNet, self).__init__() # this is not really clear to me\n",
    "        \n",
    "        self.cnn_embedding = torch.nn.Conv1d(num_input_features, num_embeddings, dim_kernel) # in channel, out channel, kernel size\n",
    "        print('still to decide the kernel size')\n",
    "        print('and how do you set the number of filters to D?')\n",
    "        print('so far I set the number of groups to num_input_features')\n",
    "        print('doing so, each input featur has its own set of filters (see documentation)')\n",
    "        self.lstm= torch.nn.LSTM(num_embeddings,  num_h)        \n",
    "        self.last_item_embedding = torch.nn.Linear(num_input_features+1,  num_embeddings)\n",
    "        # the plus one up here is the remaining capacity\n",
    "        print('also, so far you feed to the LSTM both the static and dinamic info.')\n",
    "        print('and to match the dimension, you pass this info into a fully connected layer')\n",
    "        print('you will have to change it, so to feed only the static part')\n",
    "        self.W_a = torch.tensor(torch.rand(dim_W_a,num_embeddings + num_h), requires_grad=True)\n",
    "        self.v_a = torch.tensor(torch.rand(dim_W_a), requires_grad=True)\n",
    "        self.v_a = self.v_a[None, :] # I don't know why you have to add a dimension here\n",
    "        self.W_c = torch.tensor(torch.rand(dim_W_c, 2*num_embeddings), requires_grad=True)\n",
    "        self.v_c = torch.tensor(torch.rand(dim_W_c), requires_grad=True)\n",
    "        self.v_c = self.v_c[None, :] # I don't know why you have to add a dimension here\n",
    "        # last item defines the last item you selected. \n",
    "        # it is initialized as an empty item.\n",
    "        \n",
    "        # here I set the first internal state of the RNN.\n",
    "        # I set it here and not in forwards otherwise it start with different h_0\n",
    "        # For now it's zero-initialied, but maybe there is something smarter \n",
    "        # that can be done.\n",
    "        \n",
    "        self.batch_size = batch_size \n",
    "        self.num_layers = 1\n",
    "        self.num_directions = 1\n",
    "        self.num_h = num_h\n",
    "        \n",
    "        print('Xavier Initialization still to do')\n",
    "        #print('first')\n",
    "        #print(list(self.W_a))\n",
    "        #torch.nn.init.xavier_uniform(self.W_a)\n",
    "        #print('after')\n",
    "        #print(list(self.W_a))\n",
    "        #stop\n",
    "        \n",
    "    def forward(self, x, last_item):\n",
    "\n",
    "        ReLU = torch.nn.ReLU()\n",
    "        # compuitng h_t\n",
    "        last_item = self.last_item_embedding(last_item)\n",
    "        last_item = ReLU(last_item)\n",
    "        last_item = last_item[None, :, None] # add fake batch dimension and fake Length dimension\n",
    "        \n",
    "        # here it is not clear to me why the batch size has to be one?\n",
    "        # Maybe because here you pass one info at a time??\n",
    "        h_0 = torch.zeros( self.num_layers * self.num_directions, 1, self.num_h ) \n",
    "        c_0 = torch.zeros( self.num_layers * self.num_directions, 1, self.num_h )\n",
    "        h_t, cell_t = self.lstm( last_item, (h_0,c_0) )  # if you do not provide the initial cell and state, they are by default zero.\n",
    "\n",
    "        h_t = torch.squeeze(h_t, dim = 0)    # removing the dimension seq_len since I don't know what it does\n",
    "        h_t = h_t.t()             # transposing so i have features x samples\n",
    "        # computing x_bar\n",
    "        x = x[None,:, :] # I don't know why you have to add a dimension here\n",
    "        #print(x)\n",
    "        #print(x.size())\n",
    "        x_bar = self.cnn_embedding(x)\n",
    "        print(x_bar)\n",
    "        print(x_bar.size())\n",
    "        stop\n",
    "        # concatenation of two tensors\n",
    "        Concatenations = []\n",
    "        for x_bar_i in x_bar:\n",
    "            Concatenations.append(torch.cat((x_bar_i, h_t), 0))\n",
    "        concatenation_1 = torch.stack(Concatenations, dim = 0)\n",
    "        concatenation_1 = torch.squeeze(concatenation_1, dim = 2)\n",
    "        concatenation_1 = concatenation_1.t()\n",
    "        # computing u_t\n",
    "        u_t = torch.mm(self.v_a,torch.tanh(torch.mm(self.W_a, concatenation_1))).t()  \n",
    "        # computing a_t\n",
    "        a_t = torch.nn.functional.softmax(u_t, dim = 0)        \n",
    "        # computing the context vector c_t\n",
    "        C_t_array = []\n",
    "        index = 0\n",
    "        for row in x_bar: # apaprently with split you use less grad operations\n",
    "            C_t_array.append(torch.mul(row, a_t[index]))\n",
    "            index+=1        \n",
    "        c_t = torch.stack(C_t_array,dim=0)\n",
    "        c_t = torch.sum(c_t, dim=0)        \n",
    "        # concatenation of two tensors\n",
    "        Concatenations_2 = []\n",
    "        for x_bar_i in x_bar:\n",
    "            Concatenations_2.append(torch.cat((x_bar_i, c_t), 0))\n",
    "        concatenation_2 = torch.stack(Concatenations_2, dim = 0)\n",
    "        concatenation_2 = torch.squeeze(concatenation_2, dim = 2).t()        \n",
    "        # computing u_t_tilde\n",
    "        u_t_tilde = torch.mm(self.v_c,torch.tanh(torch.mm(self.W_c, concatenation_2)))\n",
    "        # computing actual output\n",
    "        x = torch.nn.functional.softmax(u_t_tilde, dim = 1)\n",
    "        x = torch.squeeze(x, dim = 0)\n",
    "\n",
    "        return x, x_bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "still to decide the kernel size\n",
      "and how do you set the number of filters to D?\n",
      "so far I set the number of groups to num_input_features\n",
      "doing so, each input featur has its own set of filters (see documentation)\n",
      "also, so far you feed to the LSTM both the static and dinamic info.\n",
      "and to match the dimension, you pass this info into a fully connected layer\n",
      "you will have to change it, so to feed only the static part\n",
      "Xavier Initialization still to do\n",
      "('number of parameters: ', 8736)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/BigBamboo/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/Users/BigBamboo/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/Users/BigBamboo/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/Users/BigBamboo/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "input.size(-1) must be equal to input_size. Expected 32, got 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-1ec41cf823f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'number of parameters: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mNet_Actor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mlast_item\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNet_Actor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlast_item\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n\\noutput'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/BigBamboo/anaconda/lib/python2.7/site-packages/torch/nn/modules/module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-3b31283ff1b7>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, last_item)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mh_0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_layers\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_directions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_h\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mc_0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_layers\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_directions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_h\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0mh_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mlast_item\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mh_0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc_0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m  \u001b[0;31m# if you do not provide the initial cell and state, they are by default zero.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mh_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m    \u001b[0;31m# removing the dimension seq_len since I don't know what it does\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/BigBamboo/anaconda/lib/python2.7/site-packages/torch/nn/modules/module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/BigBamboo/anaconda/lib/python2.7/site-packages/torch/nn/modules/rnn.pyc\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    565\u001b[0m             \u001b[0mhx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 567\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    568\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "\u001b[0;32m/Users/BigBamboo/anaconda/lib/python2.7/site-packages/torch/nn/modules/rnn.pyc\u001b[0m in \u001b[0;36mcheck_forward_args\u001b[0;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[1;32m    517\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m         \u001b[0;31m# type: (Tensor, Tuple[Tensor, Tensor], Optional[Tensor]) -> None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 519\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    520\u001b[0m         \u001b[0mexpected_hidden_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_expected_hidden_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/BigBamboo/anaconda/lib/python2.7/site-packages/torch/nn/modules/rnn.pyc\u001b[0m in \u001b[0;36mcheck_input\u001b[0;34m(self, input, batch_sizes)\u001b[0m\n\u001b[1;32m    168\u001b[0m             raise RuntimeError(\n\u001b[1;32m    169\u001b[0m                 'input.size(-1) must be equal to input_size. Expected {}, got {}'.format(\n\u001b[0;32m--> 170\u001b[0;31m                     self.input_size, input.size(-1)))\n\u001b[0m\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_expected_hidden_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: input.size(-1) must be equal to input_size. Expected 32, got 1"
     ]
    }
   ],
   "source": [
    "#create an instance\n",
    "num_objects = 10\n",
    "Objects = GenerateANewInstance(num_objects)\n",
    "for obj in Objects:\n",
    "    if obj.Prize == 0 and obj.Weight == 0:\n",
    "        last_item = obj\n",
    "\n",
    "num_input_features = 2 # number of features of an Object\n",
    "num_embeddings = 32   # number of features for the embedding\n",
    "num_h = 32             # number of features for the hidden size of the rnn\n",
    "dim_W_a = 32           # free dimension of matrix W_a\n",
    "dim_W_c = 32           # free dimension of matrix W_c\n",
    "dim_kernel = 2        # kernel dimension\n",
    "tensors = torch.tensor([[1.1, -1.0],[2.0, 15.0],[1.0, -1.0],[20.0, 12.0],[1.0, -1.0],[2.0, 15.0],[1.0, -1.0],[20.0, 12.0],[1.0, -1.0],[2.0, 15.0],[1.0, -1.0]]).float()\n",
    "\n",
    "Net_Actor = ActorNet(num_input_features, dim_kernel, num_embeddings, num_h, dim_W_a, dim_W_c, len(tensors))\n",
    "print('number of parameters: ', sum(p.numel() for p in Net_Actor.parameters() if p.requires_grad))\n",
    "last_item = torch.tensor([0,0,1]).float()\n",
    "output = Net_Actor(tensors,last_item)\n",
    "print('\\n\\noutput')\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Critic network. \n",
    "The critic network takes as input the probabilities of the actor network and the embeddings input (x_bar). \n",
    "These two are multiplied to obtain a weighted sum of the embedded inputs.\n",
    "Then, they are fed into a network with 2 layers. \n",
    "The first layer is dense with ReLU activation and the second one is a linear layer with single output (which is the expected reward). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#class Critic(torch.nn.Module):\n",
    "#    \n",
    "#    def __init__(self, num_input_features, num_inbetween_features,len_batch):    \n",
    "#        \n",
    "#        super(Critic, self).__init__() # this is not really clear to me\n",
    "#        self.FirstLayer = torch.nn.Linear(num_input_features, num_inbetween_features)\n",
    "#        self.SecondLayer = torch.nn.Linear(num_inbetween_features*len_batch,  num_inbetween_features*len_batch)        \n",
    "#        self.SecondLayer_1 = torch.nn.Linear(num_inbetween_features*len_batch,  num_inbetween_features*len_batch)        \n",
    "#        self.SecondLayer_2 = torch.nn.Linear(num_inbetween_features*len_batch,  num_inbetween_features*len_batch)        \n",
    "#        self.LastLayer = torch.nn.Linear(num_inbetween_features*len_batch,  1)        \n",
    "#        torch.nn.init.xavier_normal_(self.FirstLayer.weight)\n",
    "#        torch.nn.init.xavier_normal_(self.SecondLayer.weight)\n",
    "#        torch.nn.init.xavier_normal_(self.SecondLayer_1.weight)\n",
    "#        torch.nn.init.xavier_normal_(self.SecondLayer_2.weight)\n",
    "#        torch.nn.init.xavier_normal_(self.LastLayer.weight)\n",
    "#        \n",
    "#    def forward(self, Outputs, Initial_Features):\n",
    "#        \n",
    "#        ReLU = torch.nn.ReLU()\n",
    "#        x_bar_critic = self.FirstLayer(Initial_Features)\n",
    "#        Outputs = torch.stack((Outputs), dim=0)\n",
    "#        OutputMeans = torch.mean(Outputs,0)        \n",
    "#        Initial_Features_average = []\n",
    "#        for i in range(len(x_bar_critic)):\n",
    "#            Initial_Features_average.append(x_bar_critic[i]*OutputMeans[i])\n",
    "#        Initial_Features_average = torch.cat((Initial_Features_average), dim=0)\n",
    "#        output = ReLU(Initial_Features_average)\n",
    "#        output = self.SecondLayer(output)\n",
    "#        output = ReLU(output)\n",
    "#        output = self.SecondLayer_1(output)\n",
    "#        output = ReLU(output)\n",
    "#        output = self.SecondLayer_2(output)\n",
    "#        output = ReLU(output)\n",
    "#        output = self.LastLayer(output)\n",
    "#        \n",
    "#        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#num_inbetween_features = 32\n",
    "num_objs = 10\n",
    "#\n",
    "#Net_critic = Critic(num_input_features, num_inbetween_features, num_objs+1)\n",
    "#print('number of critic parameters: ', sum(p.numel() for p in Net_critic.parameters() if p.requires_grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() takes exactly 8 arguments (5 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-65-f5bf3adfafa0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mNet_Actor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mActorNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_input_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_embeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_objects\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# define for how many different instances it should run, their size and the number of epochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mnum_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m250\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# create your optimizers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0moptimizer_actor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNet_Actor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() takes exactly 8 arguments (5 given)"
     ]
    }
   ],
   "source": [
    "Net_Actor = ActorNet(num_input_features, num_embeddings, num_objects+1, len(tensors))\n",
    "# define for how many different instances it should run, their size and the number of epochs\n",
    "num_epoch = 250\n",
    "# create your optimizers\n",
    "optimizer_actor = torch.optim.Adam(Net_Actor.parameters(), lr=0.01)\n",
    "Rewards = []\n",
    "Loss_actor = []\n",
    "Loss_critic = []\n",
    "# clipping the gradients\n",
    "#clip_value = 2\n",
    "#torch.nn.utils.clip_grad_norm_(Net_Actor.parameters(), clip_value)\n",
    "# fake instance\n",
    "Objects = GenerateANewInstance(num_objs)\n",
    "ObjectsFeatures = torch.tensor([[obj.Prize, obj.Weight] for obj in Objects])\n",
    "\n",
    "Outputs = []\n",
    "for e_counter in range(num_epoch):\n",
    "    optimizer_actor.zero_grad()   # zero the gradient buffers\n",
    "    total_reward = 0.0\n",
    "    total_weight = 0.0\n",
    "    sequence_probability = 1\n",
    "    Chosen = []\n",
    "    while True:\n",
    "        #print('weight', total_weight)\n",
    "        output = Net_Actor(ObjectsFeatures, total_weight,total_reward)\n",
    "        Outputs.append(output)\n",
    "        action_index = np.random.choice(range(num_objs+1),p=output.detach().numpy())\n",
    "        action_probability = output[action_index]\n",
    "        sequence_probability = sequence_probability*action_probability\n",
    "        #print('sequence probability', sequence_probability)\n",
    "        # perform action\n",
    "        total_weight+=Objects[action_index].Weight\n",
    "        total_reward+=Objects[action_index].Prize\n",
    "        Chosen.append(Objects[action_index])\n",
    "        last_item = torch.tensor(Objects[action_index].Weight,Objects[action_index].Prize,1-total_weight)\n",
    "        if total_weight > 1:\n",
    "            total_reward = -1\n",
    "            break\n",
    "        if last_item.Prize == 0 and last_item.Weight == 0:\n",
    "            total_reward= 5\n",
    "            break\n",
    "        total_reward = -1\n",
    "        break\n",
    "    #print('sequence probability', sequence_probability)\n",
    "    #print('Outputs ', Outputs)\n",
    "    #stop\n",
    "    target_actor = torch.tensor([5])\n",
    "    #target_actor.requires_grad = False\n",
    "    loss_actor = -(torch.tensor(total_reward) - target_actor)*torch.digamma(sequence_probability)\n",
    "    loss_actor = loss_actor.mean()\n",
    "    # compute gradient \n",
    "    loss_actor.backward()\n",
    "    # gradient clipping\n",
    "    clip_value = 1\n",
    "    for p in Net_Actor.parameters():\n",
    "        p.register_hook(lambda grad: torch.clamp(grad, -clip_value, clip_value))\n",
    "    # apply gradient\n",
    "    optimizer_actor.step()\n",
    "    # info for plotting\n",
    "    Rewards.append(total_reward)     \n",
    "    Loss_actor.append(loss_actor.tolist())\n",
    "    \n",
    "print('Last 5 outputs ',Outputs[-5:-1])\n",
    "R = []\n",
    "A = []\n",
    "for i in range(len(Rewards)):\n",
    "    R.append(Rewards[i])\n",
    "    A.append(Loss_actor[i])\n",
    "print('with the fake instance you\\'re testing, ')\n",
    "print('Max reward = 5 ')\n",
    "plt.figure()\n",
    "plt.plot(R)\n",
    "plt.ylabel('Rewards')\n",
    "plt.figure()\n",
    "plt.plot(A)\n",
    "plt.ylabel('Actor loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p36workshop",
   "language": "python",
   "name": "p36workshop"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
