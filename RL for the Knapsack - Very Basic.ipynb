{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this script, I try to use RL to solve the knapsack problem.\n",
    "This should not be an exciting project but just a warm up (for me at least) to understand hands-on RL, RNN, embeddings and such.\n",
    "\n",
    "The project starts with:\n",
    "- a nn to move from 2 features per object to 8\n",
    "- a LTSM with an internal state composed by 5 features\n",
    "- its output is fed to a fully connected layer that from 5 feature expands to the number of objects\n",
    "- a softmax decides which element to choose\n",
    "- If you chose objects whose weight is more than 1, the reward is -100\n",
    "- attention mechanism with glimpse\n",
    "\n",
    "Still to implement:\n",
    "- mask to not choose 'wrong' objects\n",
    "- for now, it works only wwith batches of one. Cahnge this\n",
    "\n",
    "As always, we start by importing useful libraries and defiening some boundary conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import torch \n",
    "import random\n",
    "import itertools    \n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "random.seed(1234)\n",
    "prize_min = 1\n",
    "prize_max = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we define the object class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ObjectCass:\n",
    "    \n",
    "    Prize = None\n",
    "    Weight = None\n",
    "    \n",
    "    def __init__(self, reward, weight):\n",
    "        \n",
    "        self.Prize = reward\n",
    "        self.Weight = weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we define the function to generate new instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GenerateANewInstance(num_objs):\n",
    "    \n",
    "    # fake code to control the instance I fed it.\n",
    "    # best solution = [1,0,1,0,1,0,1,0,1,0,1]\n",
    "    \n",
    "    Objects = []\n",
    "    for i in range(num_objs):\n",
    "        if i%2==1:\n",
    "            prize = 1\n",
    "            weight = 0.51\n",
    "            obj = ObjectCass(prize,weight)\n",
    "            Objects.append(obj)\n",
    "        else:\n",
    "            prize = 100\n",
    "            weight = 0.19\n",
    "            obj = ObjectCass(prize,weight)\n",
    "            Objects.append(obj)\n",
    "    Objects.append(ObjectCass(0,0)) # fake object representing that you don't pick up anything\n",
    "    \n",
    "    return Objects\n",
    "    \n",
    "    # real code    \n",
    "    \n",
    "    Objects = []\n",
    "    for i in range(num_objs):\n",
    "        prize = round(random.uniform(prize_min, prize_max), 0)\n",
    "        weight = round(random.uniform(0.01, 1), 2)\n",
    "        obj = ObjectCass(prize,weight)\n",
    "        Objects.append(obj)\n",
    "    Objects.append(ObjectCass(0,0)) # fake object representing that you don't pick up anything\n",
    "                                   # i.e. you stop picking up stuff\n",
    "    \n",
    "    return Objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actor Net. input dimension [num_obj*num_features] output dimensions [num_objects; num_objects X num_emb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActorNet(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, num_input_features, num_embeddings, num_output, batch_size):    \n",
    "        \n",
    "        super(ActorNet, self).__init__() # this is not really clear to me\n",
    "        \n",
    "        self.fc1   = torch.nn.Linear((num_input_features + 2)*batch_size, num_embeddings)\n",
    "        self.fc2   = torch.nn.Linear(num_embeddings, num_embeddings)\n",
    "        self.fc2_1 = torch.nn.Linear(num_embeddings, num_embeddings)\n",
    "        self.fc2_2 = torch.nn.Linear(num_embeddings, num_embeddings)\n",
    "        self.fc2_3 = torch.nn.Linear(num_embeddings, num_embeddings)\n",
    "        self.fc2_4 = torch.nn.Linear(num_embeddings, num_embeddings)\n",
    "        self.fc2_5 = torch.nn.Linear(num_embeddings, num_embeddings)\n",
    "        self.fc2_6 = torch.nn.Linear(num_embeddings, num_embeddings)\n",
    "        self.fc2_7 = torch.nn.Linear(num_embeddings, num_embeddings)\n",
    "        self.fc2_8 = torch.nn.Linear(num_embeddings, num_embeddings)\n",
    "        self.fc2_9 = torch.nn.Linear(num_embeddings, num_embeddings)\n",
    "        self.fc2_10 = torch.nn.Linear(num_embeddings, num_embeddings)\n",
    "        self.fc3   = torch.nn.Linear(num_embeddings, num_output)\n",
    "        torch.nn.init.xavier_normal_(self.fc1.weight, gain=0.01)\n",
    "        torch.nn.init.xavier_normal_(self.fc2.weight, gain=0.01)\n",
    "        torch.nn.init.xavier_normal_(self.fc2_1.weight, gain=0.01)\n",
    "        torch.nn.init.xavier_normal_(self.fc2_2.weight, gain=0.01)\n",
    "        torch.nn.init.xavier_normal_(self.fc2_3.weight, gain=0.01)\n",
    "        torch.nn.init.xavier_normal_(self.fc2_4.weight, gain=0.01)\n",
    "        torch.nn.init.xavier_normal_(self.fc2_5.weight, gain=0.01)\n",
    "        torch.nn.init.xavier_normal_(self.fc3.weight, gain=0.01)\n",
    "        self.batch_size = batch_size\n",
    "            \n",
    "    def forward(self, x, total_weight, total_reward):\n",
    "        \n",
    "        ReLu = torch.nn.ReLU()\n",
    "        Lista = [x_i for x_i in x]\n",
    "        for i in range(len(Lista)):\n",
    "            Lista[i] = torch.cat([Lista[i], torch.tensor([total_weight, total_reward])])\n",
    "        input_fc1 = torch.cat(Lista)\n",
    "        x = self.fc1(input_fc1)\n",
    "        x = ReLu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = ReLu(x)\n",
    "        x = self.fc2_1(x)\n",
    "        x = ReLu(x)\n",
    "        x = self.fc2_2(x)\n",
    "        x = ReLu(x)\n",
    "        x = self.fc2_3(x)\n",
    "        x = ReLu(x)\n",
    "        x = self.fc2_4(x)\n",
    "        x = ReLu(x)\n",
    "        x = self.fc2_5(x)\n",
    "        x = ReLu(x)\n",
    "        x = self.fc2_6(x)\n",
    "        x = ReLu(x)\n",
    "        x = self.fc2_7(x)\n",
    "        x = ReLu(x)\n",
    "        x = self.fc2_8(x)\n",
    "        x = ReLu(x)\n",
    "        x = self.fc2_9(x)\n",
    "        x = ReLu(x)\n",
    "        x = self.fc2_10(x)\n",
    "        x = ReLu(x)\n",
    "        #print('x fc2 - actor')\n",
    "        #print(x)\n",
    "        x = self.fc3(x)\n",
    "        #print('x fc3 - actor')\n",
    "        #print(x)\n",
    "        x = torch.nn.functional.softmax(x, dim = 0)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters:  13419\n",
      "\n",
      "\n",
      "output\n",
      "tensor([0.0822, 0.0910, 0.0971, 0.0908, 0.0788, 0.0863, 0.1005, 0.0803, 0.0899,\n",
      "        0.0948, 0.1083], grad_fn=<SoftmaxBackward>)\n"
     ]
    }
   ],
   "source": [
    "#create an instance\n",
    "num_objects = 10\n",
    "Objects = GenerateANewInstance(num_objects)\n",
    "for obj in Objects:\n",
    "    if obj.Prize == 0 and obj.Weight == 0:\n",
    "        last_item = obj\n",
    "\n",
    "num_input_features = 2 # number of features of an Object\n",
    "num_embeddings = 32    # number of features for the embedding\n",
    "num_h = 32             # number of features for the hidden size of the rnn\n",
    "dim_W_a = 32           # free dimension of matrix W_a\n",
    "dim_W_c = 32           # free dimension of matrix W_c\n",
    "tensors = torch.tensor([[1., -1.],[2., 15.],[1., -1.],[20., 12.],[1., -1.],[2., 15.],[1., -1.],[20., 12.],[1., -1.],[2., 15.],[1., -1.]])\n",
    "Net_Actor = ActorNet(num_input_features, num_embeddings, num_objects+1, len(tensors))\n",
    "print('number of parameters: ', sum(p.numel() for p in Net_Actor.parameters() if p.requires_grad))\n",
    "output = Net_Actor(tensors,0,0)\n",
    "print('\\n\\noutput')\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Critic network. \n",
    "The critic network takes as input the probabilities of the actor network and the embeddings input (x_bar). \n",
    "These two are multiplied to obtain a weighted sum of the embedded inputs.\n",
    "Then, they are fed into a network with 2 layers. \n",
    "The first layer is dense with ReLU activation and the second one is a linear layer with single output (which is the expected reward). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Critic(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, num_input_features, num_inbetween_features,len_batch):    \n",
    "        \n",
    "        super(Critic, self).__init__() # this is not really clear to me\n",
    "        self.FirstLayer = torch.nn.Linear(num_input_features, num_inbetween_features)\n",
    "        self.SecondLayer = torch.nn.Linear(num_inbetween_features*len_batch,  num_inbetween_features*len_batch)        \n",
    "        self.SecondLayer_1 = torch.nn.Linear(num_inbetween_features*len_batch,  num_inbetween_features*len_batch)        \n",
    "        self.SecondLayer_2 = torch.nn.Linear(num_inbetween_features*len_batch,  num_inbetween_features*len_batch)        \n",
    "        self.LastLayer = torch.nn.Linear(num_inbetween_features*len_batch,  1)        \n",
    "        torch.nn.init.xavier_normal_(self.FirstLayer.weight)\n",
    "        torch.nn.init.xavier_normal_(self.SecondLayer.weight)\n",
    "        torch.nn.init.xavier_normal_(self.SecondLayer_1.weight)\n",
    "        torch.nn.init.xavier_normal_(self.SecondLayer_2.weight)\n",
    "        torch.nn.init.xavier_normal_(self.LastLayer.weight)\n",
    "        \n",
    "    def forward(self, Outputs, Initial_Features):\n",
    "        \n",
    "        ReLU = torch.nn.ReLU()\n",
    "        x_bar_critic = self.FirstLayer(Initial_Features)\n",
    "        Outputs = torch.stack((Outputs), dim=0)\n",
    "        OutputMeans = torch.mean(Outputs,0)        \n",
    "        Initial_Features_average = []\n",
    "        for i in range(len(x_bar_critic)):\n",
    "            Initial_Features_average.append(x_bar_critic[i]*OutputMeans[i])\n",
    "        Initial_Features_average = torch.cat((Initial_Features_average), dim=0)\n",
    "        output = ReLU(Initial_Features_average)\n",
    "        output = self.SecondLayer(output)\n",
    "        output = ReLU(output)\n",
    "        output = self.SecondLayer_1(output)\n",
    "        output = ReLU(output)\n",
    "        output = self.SecondLayer_2(output)\n",
    "        output = ReLU(output)\n",
    "        output = self.LastLayer(output)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of critic parameters:  373217\n"
     ]
    }
   ],
   "source": [
    "num_inbetween_features = 32\n",
    "num_objs = 10\n",
    "\n",
    "Net_critic = Critic(num_input_features, num_inbetween_features, num_objs+1)\n",
    "print('number of critic parameters: ', sum(p.numel() for p in Net_critic.parameters() if p.requires_grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Net_Actor = ActorNet(num_input_features, num_embeddings, num_objects+1, len(tensors))\n",
    "# define for how many different instances it should run, their size and the number of epochs\n",
    "num_epoch = 2500\n",
    "# create your optimizers\n",
    "optimizer_actor = torch.optim.Adam(Net_Actor.parameters(), lr=0.0001)\n",
    "Rewards = []\n",
    "Loss_actor = []\n",
    "Loss_critic = []\n",
    "# clipping the gradients\n",
    "clip_value = 2\n",
    "torch.nn.utils.clip_grad_norm_(Net_Actor.parameters(), clip_value)\n",
    "# fake instance\n",
    "Objects = GenerateANewInstance(num_objs)\n",
    "ObjectsFeatures = torch.tensor([[obj.Prize, obj.Weight] for obj in Objects])\n",
    "\n",
    "Outputs = []\n",
    "for e_counter in range(num_epoch):\n",
    "    optimizer_actor.zero_grad()   # zero the gradient buffers\n",
    "    total_reward = 0.0\n",
    "    total_weight = 0\n",
    "    while True:\n",
    "        output = Net_Actor(ObjectsFeatures, total_weight,total_reward)\n",
    "        Outputs.append(output)\n",
    "        action_index = np.random.choice(range(num_objs+1),p=output.detach().numpy())\n",
    "        action_probability = output[action_index]\n",
    "        # perform action\n",
    "        if action_index != 10:\n",
    "            total_reward = -100\n",
    "            break\n",
    "        else:\n",
    "            total_reward = 100\n",
    "            break\n",
    "    target_actor = torch.tensor([100])\n",
    "    #target_actor.requires_grad = False\n",
    "    loss_actor = (torch.tensor(total_reward) - target_actor)*torch.log(action_probability)\n",
    "    loss_actor = loss_actor.mean()\n",
    "    # compute gradient \n",
    "    loss_actor.backward()\n",
    "    # apply gradient\n",
    "    optimizer_actor.step()\n",
    "\n",
    "    Rewards.append(total_reward)     \n",
    "    Loss_actor.append(loss_actor.tolist())\n",
    "    \n",
    "print('Outputs ',Outputs)\n",
    "R = []\n",
    "A = []\n",
    "for i in range(len(Rewards)):\n",
    "    R.append(Rewards[i])\n",
    "    A.append(Loss_actor[i])\n",
    "print('with the fake instance you\\'re testing, ')\n",
    "print('Max reward = 500 ')\n",
    "plt.figure()\n",
    "plt.plot(R)\n",
    "plt.ylabel('Rewards')\n",
    "plt.figure()\n",
    "plt.plot(A)\n",
    "plt.ylabel('Actor loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stophere"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define the parameters of the actor network and we create it. We also take a look at the number of trainable variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN_Attention(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, num_input_features, dim_kernel, num_embeddings, num_h, dim_W_a, dim_W_c, batch_size):    \n",
    "        \n",
    "        super(RNN_Attention, self).__init__() # this is not really clear to me\n",
    "        \n",
    "        self.cnn_embedding = torch.nn.Conv1d(num_input_features, num_embeddings, dim_kernel) # in channel, out channel, kernel size\n",
    "        print('still to decide the kernel size')\n",
    "        print('and how do you set the number of filters to D?')\n",
    "        print('so far I set the number of groups to num_input_features')\n",
    "        print('doing so, each input featur has its own set of filters (see documentation)')\n",
    "        self.lstm= torch.nn.LSTM(num_embeddings,  num_h)        \n",
    "        self.last_item_embedding = torch.nn.Linear(num_input_features,  num_embeddings)        \n",
    "        print('also, so far you feed to the LSTM both the static and dinamic info.')\n",
    "        print('and to match the dimension, you pass this info into a fully connected layer')\n",
    "        print('you will have to change it, so to feed only the static part')\n",
    "        self.W_a = torch.tensor(torch.rand(dim_W_a,num_embeddings + num_h), requires_grad=True)\n",
    "        self.v_a = torch.tensor(torch.rand(dim_W_a), requires_grad=True)\n",
    "        self.v_a = self.v_a[None, :] # I don't know why you have to add a dimension here\n",
    "        self.W_c = torch.tensor(torch.rand(dim_W_c, 2*num_embeddings), requires_grad=True)\n",
    "        self.v_c = torch.tensor(torch.rand(dim_W_c), requires_grad=True)\n",
    "        self.v_c = self.v_c[None, :] # I don't know why you have to add a dimension here\n",
    "        # last item defines the last item you selected. \n",
    "        # it is initialized as an empty item.\n",
    "        \n",
    "        # here I set the first internal state of the RNN.\n",
    "        # I set it here and not in forwards otherwise it start with different h_0\n",
    "        # For now it's zero-initialied, but maybe there is something smarter \n",
    "        # that can be done.\n",
    "        \n",
    "        self.batch_size = batch_size \n",
    "        self.num_layers = 1\n",
    "        self.num_directions = 1\n",
    "        self.num_h = num_h\n",
    "        \n",
    "        print('Xavier Initialization still to do')\n",
    "        #print('first')\n",
    "        #print(list(self.W_a))\n",
    "        #torch.nn.init.xavier_uniform(self.W_a)\n",
    "        #print('after')\n",
    "        #print(list(self.W_a))\n",
    "        #stop\n",
    "        \n",
    "    def forward(self, x, last_item):\n",
    "\n",
    "        # also this is to change (why it does not work if I assign the fucntion directly?)\n",
    "        ReLU = torch.nn.ReLU()\n",
    "        # compuitng h_t\n",
    "        last_item = self.last_item_embedding(torch.tensor([last_item.Prize, last_item.Weight]).float())\n",
    "        last_item = ReLU(last_item)\n",
    "        last_item = last_item[None, None, :] # I don't know why you have to add a dimension here\n",
    "        \n",
    "        # here it is not clear to me why the batch size has to be one?\n",
    "        # Maybe because here you pass one info at a time??\n",
    "        h_0 = torch.zeros( self.num_layers * self.num_directions, 1, self.num_h ) \n",
    "        c_0 = torch.zeros( self.num_layers * self.num_directions, 1, self.num_h )\n",
    "        h_t, cell_t = self.lstm( last_item, (h_0,c_0) )  # if you do not provide the initial cell and state, they are by default zero.\n",
    "\n",
    "        h_t = torch.squeeze(h_t, dim = 0)    # removing the dimension seq_len since I don't know what it does\n",
    "        h_t = h_t.t()             # transposing so i have features x samples\n",
    "        # computing x_bar\n",
    "        x = x[:, :, None] # I don't know why you have to add a dimension here\n",
    "        x_bar = self.cnn_embedding(x)\n",
    "        # concatenation of two tensors\n",
    "        Concatenations = []\n",
    "        for x_bar_i in x_bar:\n",
    "            Concatenations.append(torch.cat((x_bar_i, h_t), 0))\n",
    "        concatenation_1 = torch.stack(Concatenations, dim = 0)\n",
    "        concatenation_1 = torch.squeeze(concatenation_1, dim = 2)\n",
    "        concatenation_1 = concatenation_1.t()\n",
    "        # computing u_t\n",
    "        u_t = torch.mm(self.v_a,torch.tanh(torch.mm(self.W_a, concatenation_1))).t()  \n",
    "        # computing a_t\n",
    "        a_t = torch.nn.functional.softmax(u_t, dim = 0)        \n",
    "        # computing the context vector c_t\n",
    "        C_t_array = []\n",
    "        index = 0\n",
    "        for row in x_bar: # apaprently with split you use less grad operations\n",
    "            C_t_array.append(torch.mul(row, a_t[index]))\n",
    "            index+=1        \n",
    "        c_t = torch.stack(C_t_array,dim=0)\n",
    "        c_t = torch.sum(c_t, dim=0)        \n",
    "        # concatenation of two tensors\n",
    "        Concatenations_2 = []\n",
    "        for x_bar_i in x_bar:\n",
    "            Concatenations_2.append(torch.cat((x_bar_i, c_t), 0))\n",
    "        concatenation_2 = torch.stack(Concatenations_2, dim = 0)\n",
    "        concatenation_2 = torch.squeeze(concatenation_2, dim = 2).t()        \n",
    "        # computing u_t_tilde\n",
    "        u_t_tilde = torch.mm(self.v_c,torch.tanh(torch.mm(self.W_c, concatenation_2)))\n",
    "        # computing actual output\n",
    "        x = torch.nn.functional.softmax(u_t_tilde, dim = 1)\n",
    "        x = torch.squeeze(x, dim = 0)\n",
    "\n",
    "        return x, x_bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create an instance\n",
    "num_objects = 10\n",
    "Objects = GenerateANewInstance(num_objects)\n",
    "for obj in Objects:\n",
    "    if obj.Prize == 0 and obj.Weight == 0:\n",
    "        last_item = obj\n",
    "\n",
    "\n",
    "num_input_features = 2 # number of features of an Object\n",
    "dim_kernel = 1         # kernel dimension (since there are only two features, kerneal dimension = 1)\n",
    "num_embeddings = 32    # number of features for the embedding\n",
    "num_h = 32             # number of features for the hidden size of the rnn\n",
    "dim_W_a = 32           # free dimension of matrix W_a\n",
    "dim_W_c = 32           # free dimension of matrix W_c\n",
    "tensors = torch.tensor([[1., -1.],[2., 15.],[1., -1.],[20., 12.],[1., -1.],[2., 15.],[1., -1.],[20., 12.],[1., -1.],[2., 15.],[1., -1.]])\n",
    "#Net = RNN_Attention(num_input_features, dim_kernel, num_embeddings, num_h, dim_W_a, dim_W_c, len(tensors))\n",
    "Net = ActorNet(num_input_features, num_embeddings, num_h, num_objects+1, len(tensors))\n",
    "\n",
    "print('number of parameters: ', sum(p.numel() for p in Net.parameters() if p.requires_grad))\n",
    "output, x_bar = Net(tensors, last_item)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Critic(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, num_input_features, num_inbetween_features):    \n",
    "        \n",
    "        super(Critic, self).__init__() # this is not really clear to me\n",
    "        self.FirstLayer = torch.nn.Linear(num_input_features, num_inbetween_features)\n",
    "        self.SecondLayer = torch.nn.Linear(num_inbetween_features,  1)        \n",
    "            \n",
    "    def forward(self, Average_x_bar):\n",
    "        \n",
    "        # change this when you consider batch > 1\n",
    "        Average_x_bar = torch.squeeze(Average_x_bar)\n",
    "        ReLU = torch.nn.ReLU()\n",
    "        #weighted_sum = weighted_sum.squeeze()\n",
    "        output = self.FirstLayer(Average_x_bar)\n",
    "        output = ReLU(output)\n",
    "        output = self.SecondLayer(output)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_inbetween_features = 32\n",
    "num_objs = 10\n",
    "Net_critic = Critic(num_embeddings*(num_objs+1), num_inbetween_features)\n",
    "print('just for the easy testing, use only the outputs without embeddings')\n",
    "Net_critic = Critic(1*(num_objs+1), num_inbetween_features)\n",
    "print('number of critic parameters: ', sum(p.numel() for p in Net_critic.parameters() if p.requires_grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('CHANGE LAST_ITEM SUCH THAT IT ALSO EMBEDDS THE REMAINING AVAILABLE CAPACITY')\n",
    "print('change the mask such that it does not even feed old element to the Net')\n",
    "print('check again the probability thing.')\n",
    "print('I don\\'t think it\\'s the probability of the last action but the probability of the whole sequence')\n",
    "print('THERE IS A FUNCTION CALLED MASK. CHECK IT OUT')\n",
    "print('check clip value for negative values also')\n",
    "print('metti Xavier\\'s inizializazione')\n",
    "\n",
    "# define for how many different instances it should run, their size and the number of epochs\n",
    "num_instances = 1\n",
    "num_epoch = 100\n",
    "\n",
    "# define the loss criterion\n",
    "criterion = torch.nn.MSELoss()\n",
    "# create your optimizers\n",
    "optimizer_actor = torch.optim.SGD(Net.parameters(), lr=0.01)\n",
    "optimizer_critic = torch.optim.SGD(Net_critic.parameters(), lr=0.01)\n",
    "Rewards = []\n",
    "Loss_actor = []\n",
    "Loss_critic = []\n",
    "\n",
    "# clipping the gradients\n",
    "clip_value = 2\n",
    "torch.nn.utils.clip_grad_value_(Net.parameters(), clip_value)\n",
    "torch.nn.utils.clip_grad_value_(Net_critic.parameters(), clip_value)\n",
    "\n",
    "for e_counter in range(num_epoch):\n",
    "    for i_counter in range(num_instances):\n",
    "        Objects = GenerateANewInstance(num_objs)\n",
    "        ObjectsFeatures = torch.tensor([[obj.Prize, obj.Weight] for obj in Objects])\n",
    "        last_item = Objects[-1]\n",
    "        Chosen = []\n",
    "        Outputs = []\n",
    "        total_reward = 0.0\n",
    "        total_weight = 0\n",
    "        total_steps = 0\n",
    "        while total_steps < num_objs+1:\n",
    "            total_steps += 1\n",
    "            output, x_bar = Net(ObjectsFeatures,last_item)\n",
    "            Outputs.append(output)\n",
    "            ###################\n",
    "            # MASK IS MISSING #\n",
    "            ###################\n",
    "            # choose action\n",
    "            action_index = torch.argmax(output)\n",
    "            # perform action\n",
    "            total_weight+=Objects[action_index].Weight\n",
    "            total_reward+=Objects[action_index].Prize\n",
    "            Chosen.append(Objects[action_index])\n",
    "            last_item = Objects[action_index]\n",
    "            if total_weight > 1:\n",
    "                total_reward = -1\n",
    "                break\n",
    "            if last_item.Prize == 0 and last_item.Weight == 0:\n",
    "                #total_reward= -100\n",
    "                break\n",
    "        Rewards.append(total_reward)\n",
    "        #print(Chosen[0].Prize)\n",
    "        #stop\n",
    "        \n",
    "    \n",
    "    optimizer_actor.zero_grad()   # zero the gradient buffers\n",
    "    optimizer_critic.zero_grad()  # zero the gradient buffers\n",
    "    # compute input for critic network\n",
    "    Outputs = torch.stack((Outputs), dim=0)\n",
    "    OutputMeans = torch.mean(Outputs,0)\n",
    "    Averaged_x_bar = []\n",
    "    for i in range(len(x_bar)):\n",
    "        Averaged_x_bar.append(x_bar[i]*OutputMeans[i])\n",
    "    print(Averaged_x_bar)\n",
    "    Averaged_x_bar = torch.cat((Averaged_x_bar), dim=0)\n",
    "    # compute target for critic network\n",
    "    target = Net_critic(Averaged_x_bar)\n",
    "    if torch.isnan(target):\n",
    "        print('taget is Nan')\n",
    "        print(target)\n",
    "        error_Nan\n",
    "    target_tensor = torch.tensor([total_reward], dtype=torch.float32)\n",
    "    target_tensor.requires_grad = True # I don t understand why this has to be put to true\n",
    "    # loss critic\n",
    "    loss_critic = criterion(target, target_tensor)\n",
    "    loss_critic = loss_critic/num_instances\n",
    "    loss_critic.backward(retain_graph=True)    \n",
    "    Loss_critic.append(loss_critic.tolist())\n",
    "    # loss actor\n",
    "    loss_actor = (torch.tensor(total_reward) - target)*torch.log(output)\n",
    "    loss_actor = loss_actor.mean()\n",
    "    Loss_actor.append(loss_actor.tolist())\n",
    "    # update actor\n",
    "    loss_actor.backward()\n",
    "    optimizer_critic.step()    # Does the update\n",
    "    optimizer_actor.step()    # Does the update\n",
    "    #print('iteration number ', e_counter)\n",
    "\n",
    "R = []\n",
    "A = []\n",
    "C = []\n",
    "for i in range(len(Rewards)):\n",
    "    if Rewards.index(Rewards[i]) == 0:\n",
    "        R.append(Rewards[i])\n",
    "        A.append(Loss_actor[i])\n",
    "        C.append(Loss_critic[i])\n",
    "print('with the fake instance you\\'re testing, ')\n",
    "print('Max reward = 500 ')\n",
    "plt.figure()\n",
    "plt.plot(R)\n",
    "plt.figure()\n",
    "plt.plot(A)\n",
    "plt.figure()\n",
    "plt.plot(C)\n",
    "print(R)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
